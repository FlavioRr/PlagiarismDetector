{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Obtaining dependency information for imblearn from https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Obtaining dependency information for imbalanced-learn from https://files.pythonhosted.org/packages/5a/fa/267de06c95210580f4b82b45cec1ce1e9ce1f21a01a684367db89e7da70d/imbalanced_learn-0.12.3-py3-none-any.whl.metadata\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\flavio ruvalcaba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn->imblearn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\flavio ruvalcaba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn->imblearn) (1.11.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\flavio ruvalcaba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\flavio ruvalcaba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\flavio ruvalcaba\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "   ---------------------------------------- 0.0/258.3 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 20.5/258.3 kB 682.7 kB/s eta 0:00:01\n",
      "   -------------- ------------------------- 92.2/258.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 258.3/258.3 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.3 imblearn-0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\Flavio Ruvalcaba\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def load_files_from_directory(directory):\n",
    "    files = []\n",
    "    labels = []\n",
    "    for root, _, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            with open(os.path.join(root, filename), 'r', encoding='utf-8') as f:\n",
    "                files.append(f.read())\n",
    "                if 'plagio' in root:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "    return files, labels\n",
    "\n",
    "# Paths de las carpetas de datos\n",
    "test_noplag_path = r\"C:\\Users\\Flavio Ruvalcaba\\Documents\\Escuela\\Universidad\\8Semestre\\PlagiarismDetector\\finalDataset\\split\\test\\noplag\"\n",
    "test_plagio_path = r\"C:\\Users\\Flavio Ruvalcaba\\Documents\\Escuela\\Universidad\\8Semestre\\PlagiarismDetector\\finalDataset\\split\\test\\plagio\"\n",
    "train_noplag_path = r\"C:\\Users\\Flavio Ruvalcaba\\Documents\\Escuela\\Universidad\\8Semestre\\PlagiarismDetector\\finalDataset\\split\\train\\noplag\"\n",
    "train_plagio_path = r\"C:\\Users\\Flavio Ruvalcaba\\Documents\\Escuela\\Universidad\\8Semestre\\PlagiarismDetector\\finalDataset\\split\\train\\plagio\"\n",
    "\n",
    "# Cargar datos de entrenamiento y prueba\n",
    "train_files_noplag, train_labels_noplag = load_files_from_directory(train_noplag_path)\n",
    "train_files_plagio, train_labels_plagio = load_files_from_directory(train_plagio_path)\n",
    "test_files_noplag, test_labels_noplag = load_files_from_directory(test_noplag_path)\n",
    "test_files_plagio, test_labels_plagio = load_files_from_directory(test_plagio_path)\n",
    "\n",
    "# Combinar datos de entrenamiento y prueba\n",
    "train_files = train_files_noplag + train_files_plagio\n",
    "train_labels = train_labels_noplag + train_labels_plagio\n",
    "test_files = test_files_noplag + test_files_plagio\n",
    "test_labels = test_labels_noplag + test_labels_plagio\n",
    "\n",
    "# Transformación TF-IDF con bigramas y eliminación de stopwords\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "X_train = vectorizer.fit_transform(train_files)\n",
    "X_test = vectorizer.transform(test_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancear los datos de entrenamiento usando SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Mejores parámetros: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir los parámetros para el grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# Ajustar el grid search al conjunto de entrenamiento balanceado\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Mejor conjunto de hiperparámetros\n",
    "print(f\"Mejores parámetros: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.39      0.48       146\n",
      "           1       0.73      0.87      0.79       270\n",
      "\n",
      "    accuracy                           0.70       416\n",
      "   macro avg       0.67      0.63      0.64       416\n",
      "weighted avg       0.69      0.70      0.68       416\n",
      "\n",
      "Validación cruzada accuracy: 0.7554 ± 0.1113\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el mejor modelo encontrado por GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "\n",
    "# Evaluar el modelo con validación cruzada\n",
    "cv_scores = cross_val_score(best_model, X_train_balanced, y_train_balanced, cv=5, scoring='accuracy')\n",
    "print(f\"Validación cruzada accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
